# pyLRp grammar file for pyLRp
# this must be kept parsable with the limited bootstrap parser
# it is the definite reference on the format

import pyLRp

%lexer

%x INDENT

# states used for correct inline python handling
%x PYBLOB, PYBLOBNOSPC, MLSTRD, MLSTRS, PYINLINE

# states used by the autoaction spec
%x AST

# states used by the lexer spec
%x LEXER, CONDSPEC, REGEX, DEF, DEFINDENT, LEXACTION, SCOPE, SCOPEDEF, DEFNEWLINE

# states used by the parser spec
%x PARSER, FIXITYSPEC, PARSERMETA, PARSERULE, PARSERINDENT

# states used by the footer
%x FOOTER

# symbol list states
%x SYMBOLLIST

# match the empty string as empty indentation
%nullmatch INDENT

%def
    space     [\ \t\v\f]
    regexchar [^\ \t\v\f\n]
    regex     ({regexchar}|\\\ )+
    tonewline [^\n]*
    name      [a-zA-Z_][a-zA-Z0-9_]*
    comment   {space}*(\#{tonewline})?
    stoken    "([^\"]|\\\")+"|'([^\']|\\\')+'

#######################################################
# section switching and uniform empty line ignorance
#######################################################
<$SOL,LEXER>%ast{comment}\n    %begin(AST), AST
<$SOL,AST>%lexer{comment}\n    %begin(LEXER), LEXER
<$SOL,LEXER,AST>%parser{comment}\n %begin(PARSER), PARSER
<LEXER,AST,PARSER>%footer{comment}\n %begin(FOOTER), FOOTER

<LEXER,PARSER,AST,INDENT>{comment}\n  %restart
<INDENT>[\ \t]* %function(indent), %restart

# two never matching rules to define terminal symbols
# generated programatically (by the indent function in %footer)
[] INDENT
[] DEDENT

#######################################################
# header and footer: PYVERB
#######################################################
<FOOTER,$INITIAL>[^\n]*\n PYVERB

#######################################################
# commonly used syntactic contructs
#######################################################
<SYMBOLLIST,FIXITYSPEC>{space}+    %restart
<SYMBOLLIST,FIXITYSPEC>{comment}\n %pop(), NEWLINE
<SYMBOLLIST,FIXITYSPEC>\\\n        %restart
<SYMBOLLIST,FIXITYSPEC>,           COMMA
<SYMBOLLIST,FIXITYSPEC>{name}      SYMBOL

# fixityspecs allow stokens to appear in the list
<FIXITYSPEC>{stoken}               SYMBOL

#######################################################
# the lexer spec
#######################################################
<LEXER>%x %push(SYMBOLLIST), EXCLUSIVE
<LEXER>%s %push(SYMBOLLIST), INCLUSIVE
<LEXER>%nullmatch %push(SYMBOLLIST), NULLMATCH
<LEXER>%def{comment}\n %push(DEF), %push(INDENT), DEF
<LEXER,SCOPE>%scope %push(SCOPEDEF), SCOPE
<LEXER>\< %push(CONDSPEC), LANGLE
<LEXER>^  %push(LEXACTION), %push(REGEX), CARET
<LEXER>[^\^\<\%\s]({regexchar}|(\\\ ))* %push(LEXACTION), REGEX

<DEF>{name} SYMBOL
# this is the space separating the name and the newline
<DEF>{space}+ %begin(DEFNEWLINE), %push(REGEX), %restart
<DEFNEWLINE>{comment}\n %begin(DEF), %push(DEF), %push(INDENT), NEWLINE


<SCOPEDEF>{space}+ %restart
<SCOPEDEF>,        COMMA
<SCOPEDEF>{name}|$SOL|$SOF|$INITIAL SYMBOL
<SCOPEDEF>\+        PLUS
<SCOPEDEF>-        MINUS
<SCOPEDEF>\(       OPAREN
<SCOPEDEF>\)       CPAREN
<SCOPEDEF>{comment}\n %begin(SCOPE), %push(INDENT), %restart

<SCOPE>[^\%\n\s]({regexchar}|(\\\ ))* REGEX
<SCOPE>{space}+ %push(SCOPE), %push(INDENT), %push(LEXACTION), %restart

<CONDSPEC>{name}|$SOL|$SOF|$INITIAL SYMBOL
<CONDSPEC>,        COMMA
<CONDSPEC>{space}+ %restart
<CONDSPEC>\>       %begin(LEXACTION), %push(REGEX), RANGLE

<REGEX>{regex}  %pop(), REGEX

<LEXACTION>{space}+ %restart
<LEXACTION>,        COMMA
<LEXACTION>%push    PUSH
<LEXACTION>%pop     POP
<LEXACTION>%begin   BEGIN
<LEXACTION>%continue CONTINUE
<LEXACTION>%restart RESTART
<LEXACTION>%debug   DEBUG
<LEXACTION>"([^\"\n]|\\\")*" STRLIT
<LEXACTION>%function FUNCTION
<LEXACTION>{name}   SYMBOL
<LEXACTION>\(       OPAREN
<LEXACTION>\)       CPAREN
<LEXACTION>{comment}\n %pop(), NEWLINE
<LEXACTION>\\\n     %restart


#######################################################
# the grammar spec
#######################################################
<PARSER>{name}    %begin(PARSERMETA), SYMBOL
<PARSER>%left     %push(FIXITYSPEC),  LEFT
<PARSER>%right    %begin(FIXITYSPEC), RIGHT
<PARSER>%nonassoc %begin(FIXITYSPEC), NONASSOC
<PARSERMETA>:{comment} %begin(PARSER), %push(PARSERULE), %push(INDENT), COLON

<PARSERULE>{name}    SYMBOL
<PARSERULE>{stoken}  STOKEN
<PARSERULE>%empty    EMPTY
<PARSERULE>%prec     PREC
<PARSERULE>\(        OPAREN
<PARSERULE>\)        CPAREN
<PARSERULE>{space}+  %restart
<PARSERULE>\\\n      %restart
<PARSERULE>\n        %push(PARSERULE), %push(INDENT), NEWLINE
<PARSERULE>:         %push(PYINLINE), COLON

<PYINLINE>{space}+ %restart
<PYINLINE>{comment}\n %begin(PYBLOB), %push(INDENT), %restart
<PYINLINE>[^\#\n]{tonewline}\n %push(INDENT), PYSINGLE

#######################################################
# multiline python actions
#######################################################

# python strings, we must not alter their contents
# and must ignore leading whitespace and stuff within
<PYBLOB,PYBLOBNOSPC>[bu]?r?\"\"\" %push(MLSTRD), PYBLOB
<PYBLOB,PYBLOBNOSPC>[bu]?r?"([^\"\n]|\"|\\\n)*" PYBLOB
<PYBLOB,PYBLOBNOSPC>[bu]?r?\'\'\' %push(MLSTRS), PYBLOB
<PYBLOB,PYBLOBNOSPC>[bu]?r?'([^\']|\\\'|\\\n)*' PYBLOB

<MLSTRD>(\"|\"\"|[^\"\\]*)(\\\"|\\[^\"])? PYBLOB
<MLSTRD>\"\"\" %pop(), PYBLOB
<MLSTRD>(\'|\'\'|[^\'\\]*)(\\\'|\\[^\'])? PYBLOB
<MLSTRS>\'\'\' %pop(), PYBLOB

# this idea comes directly from the CPython lexer
# count grouping operators to tell whether the linebreak counts
<PYBLOB,PYBLOBNOSPC>[\(\[\{] %push(PYBLOBNOSPC), PYBLOB
<PYBLOB,PYBLOBNOSPC>[\)\]\}] %pop(), PYBLOB

<PYBLOB,PYBLOBNOSPC>[a-zA-Z_][a-zA-Z0-9_]* PYBLOB
<PYBLOB,PYBLOBNOSPC>0x[0-9a-fA-F]+|0o[0-7]+|[0-9]+ PYBLOB
<PYBLOB,PYBLOBNOSPC>[=+\-*/\\.:,@<>%&|=^]+ PYBLOB
<PYBLOB,PYBLOBNOSPC>$[0-9]+|$$ STACKVAR

# explicit line continuations
<PYBLOB,PYBLOBNOSPC>\\\n PYBLOB

# preserve insignificant space
<PYBLOBNOSPC>\s+ PYBLOB
<PYBLOBNOSPC,PYBLOB>{comment} PYBLOB
<PYBLOB>{space}+ PYBLOB

# discern indentation
<PYBLOB>\n %push(PYBLOB), %push(INDENT), %restart

%parser

file:
    init header lexer parser optfooter
    init header lexer optfooter
    init header parser optfooter

init:
    %empty:
        self.syntax = pyLRp.Syntax()
        self.assocDefs = {}
        self.assocPower = 0
        self.productionNumber = 0

        self.undef = {}
        self.defined = set()

symbollist:
    symbollist_ NEWLINE

symbollist_:
    SYMBOL:                   $$.sem = [$1.sem]
    symbollist_ COMMA SYMBOL: $$.sem = $1.sem + [$3.sem]
    symbollist_ SYMBOL:       $$.sem = $1.sem + [$2.sem]

pyblob:
    PYSINGLE
    PYBLOB
    STACKVAR
    INDENT pyblob DEDENT
    pyblob PYBLOB
    pyblob STACKVAR
    pyblob INDENT pyblob DEDENT

header:
    %empty
    header PYVERB: self.syntax.AddHeader($2.sem)

lexer:
    LEXER lexdecs lexrules

lexdecs:
    %empty
    lexdecs lexdec

lexdec:
    EXCLUSIVE symbollist
    INCLUSIVE symbollist
    NULLMATCH symbollist
    DEF INDENT lexdefs DEDENT

lexdefs:
    SYMBOL REGEX NEWLINE
    lexdefs SYMBOL REGEX NEWLINE

lexrules:
    %empty
    lexrules lexrule

lexrule:
    lexscope
    REGEX lexaction
    LANGLE condspec RANGLE REGEX lexaction

lexscope:
    SCOPE OPAREN scopespec CPAREN INDENT lexscope_ DEDENT

scopespec:
    SYMBOL
    MINUS SYMBOL
    PLUS SYMBOL
    scopespec COMMA SYMBOL
    scopespec COMMA MINUS SYMBOL
    scopespec COMMA PLUS SYMBOL

lexscope_:
    lexscope
    REGEX lexaction
    lexscope_ lexscope
    lexscope_ REGEX lexaction

condspec:
    SYMBOL
    condspec COMMA SYMBOL

lexaction:
    stackactions final NEWLINE

stackactions:
    %empty
    stackactions PUSH OPAREN SYMBOL CPAREN COMMA
    stackactions POP OPAREN CPAREN COMMA
    stackactions BEGIN OPAREN SYMBOL CPAREN COMMA
    stackactions FUNCTION OPAREN SYMBOL CPAREN COMMA
    stackactions DEBUG OPAREN STRLIT CPAREN COMMA

final:
    RESTART
    CONTINUE
    SYMBOL

parser:
    PARSER assocdefs
    parser ruleset DEDENT

assocdefs:
    %empty
    assocdefs assocdef

assocdef:
    LEFT symbollist
    RIGHT symbollist
    NONASSOC symbollist

ruleset:
    SYMBOL COLON INDENT
    ruleset parserule

parserule:
    production COLON pyblob
    production NEWLINE

production:
    SYMBOL
    EMPTY
    STOKEN
    production PREC OPAREN SYMBOL CPAREN
    production SYMBOL
    production EMPTY
    production STOKEN

optfooter:
    %empty
    footer

footer:
    FOOTER
    footer PYVERB: self.syntax.AddFooter($2.sem)

%footer

def indent(lexer, text, position):
    if not hasattr(lexer, 'indent_stack'):
        lexer.indent_stack = [0]

    if len(text) > lexer.indent_stack[-1]:
        lexer.indent_stack.append(len(text))
        lexer.nextCond.pop()
        lexer.push_back((lexer.TOKEN_NUMBERS['INDENT'], text, position))
        return

    # pop the state pushed on INDENT
    lexer.nextCond.pop()

    cnt = 0
    try:
        while lexer.indent_stack.pop() != len(text):
            cnt += 1
    except IndexError:
        return (lexer.TOKEN_NUMBERS['$ERROR'], text, position)

    lexer.indent_stack.append(len(text))

    for i in range(cnt):
        # pop one further state per DEDENT
        lexer.nextCond.pop()
        lexer.push_back((lexer.TOKEN_NUMBERS['DEDENT'], text, position))

    lexer.nextCond.pop()

if __name__ == '__main__':
    import sys
    l = Lexer(open(sys.argv[2], 'r'))

    if sys.argv[1] == '-l':
        token_type = -1
        while token_type != Lexer.TOKEN_NUMBERS['$EOF']:
            token_type, lexeme, position = l.lex()
            print(Lexer.TOKEN_NAMES[token_type], '"""{}"""'.format(lexeme), l.nextCond)
    elif sys.argv[1] == '-p':
        p = Parser(l)
        try:
            p.Parse()
        except SyntaxError as e:
            print(str(e))

